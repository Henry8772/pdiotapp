{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils.preprocess import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "exported_path = '../exported_models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_directory = \"../assets/Respeck\"\n",
    "\n",
    "data_list = []\n",
    "label_list = []\n",
    "total_rows = 0\n",
    "\n",
    "for folder_name in os.listdir(input_directory):\n",
    "    folder_path = os.path.join(input_directory, folder_name)\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith(\".csv\") and \"unprocessed\" not in file:\n",
    "            \n",
    "            filename = os.path.join(folder_path, file)\n",
    "            label, _, _ = extract_activity_and_status(filename)\n",
    "\n",
    "            df = pd.read_csv(filename, usecols=[1,2,3])\n",
    "\n",
    "            # Determine the number of rows to take from this file\n",
    "            rows_to_take = min(700 - total_rows, len(df))\n",
    "            \n",
    "            # Update the df to only contain the necessary rows and update our counter\n",
    "            df = df.head(rows_to_take)\n",
    "            label_list.append(label)\n",
    "            data_list.append(df)\n",
    "\n",
    "# all_data = pd.concat(data_list, ignore_index=True)\n",
    "# print(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalizing sensor readings\n",
    "scaler = StandardScaler()\n",
    "\n",
    "sensor_columns = ['accel_x', 'accel_y', 'accel_z']\n",
    "\n",
    "scaler.fit(data_list[0][sensor_columns])\n",
    "\n",
    "for i in range(len(data_list)):\n",
    "    data_list[i][sensor_columns] = scaler.transform(data_list[i][sensor_columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Convert data and labels to numpy arrays\n",
    "X = np.array([df.values for df in data_list])\n",
    "X = np.stack(X)\n",
    "y = LabelEncoder().fit_transform(label_list)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Convert X_train to float32\n",
    "X_train = X_train.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44, 700, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.5879586,  5.4754386, 10.459733 ],\n",
       "       [-3.4432669,  5.530121 , 10.207237 ],\n",
       "       [-3.445639 ,  5.565503 , 10.274356 ],\n",
       "       ...,\n",
       "       [-4.010174 ,  5.07015  ,  9.590381 ],\n",
       "       [-3.929526 ,  5.092666 ,  9.577597 ],\n",
       "       [-3.936642 ,  5.092666 ,  9.69905  ]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input shape\n",
    "input_shape = (700, 3)  # Each input sequence contains 700 time steps with 3 features.\n",
    "\n",
    "# Number of categories\n",
    "num_classes = 12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 13.2598 - accuracy: 0.0286 - val_loss: 5.6800 - val_accuracy: 0.1111\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.3247 - accuracy: 0.0857 - val_loss: 6.3671 - val_accuracy: 0.1111\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.1922 - accuracy: 0.3143 - val_loss: 4.6727 - val_accuracy: 0.4444\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.2547 - accuracy: 0.5714 - val_loss: 4.8393 - val_accuracy: 0.4444\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 3.0573 - accuracy: 0.6000 - val_loss: 5.1918 - val_accuracy: 0.3333\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.3949 - accuracy: 0.6571 - val_loss: 6.0723 - val_accuracy: 0.2222\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.4126 - accuracy: 0.6286 - val_loss: 4.3366 - val_accuracy: 0.3333\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.4135 - accuracy: 0.7429 - val_loss: 4.1206 - val_accuracy: 0.3333\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.1904 - accuracy: 0.7429 - val_loss: 4.2899 - val_accuracy: 0.2222\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.1451 - accuracy: 0.7429 - val_loss: 4.2333 - val_accuracy: 0.3333\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.0260 - accuracy: 0.8286 - val_loss: 4.2243 - val_accuracy: 0.3333\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8738 - accuracy: 0.8571 - val_loss: 4.2866 - val_accuracy: 0.3333\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7661 - accuracy: 0.8286 - val_loss: 4.3208 - val_accuracy: 0.3333\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7198 - accuracy: 0.8286 - val_loss: 4.3527 - val_accuracy: 0.3333\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6447 - accuracy: 0.8000 - val_loss: 4.4055 - val_accuracy: 0.3333\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5304 - accuracy: 0.9143 - val_loss: 4.5664 - val_accuracy: 0.3333\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4541 - accuracy: 0.9143 - val_loss: 4.7925 - val_accuracy: 0.3333\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4111 - accuracy: 0.9143 - val_loss: 5.0251 - val_accuracy: 0.3333\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3731 - accuracy: 0.9143 - val_loss: 5.2716 - val_accuracy: 0.3333\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3324 - accuracy: 0.9143 - val_loss: 5.4551 - val_accuracy: 0.3333\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2890 - accuracy: 0.9143 - val_loss: 5.5840 - val_accuracy: 0.3333\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2501 - accuracy: 0.9714 - val_loss: 5.6733 - val_accuracy: 0.3333\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2212 - accuracy: 0.9714 - val_loss: 5.7257 - val_accuracy: 0.3333\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1983 - accuracy: 0.9714 - val_loss: 5.7558 - val_accuracy: 0.3333\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1788 - accuracy: 0.9714 - val_loss: 5.7734 - val_accuracy: 0.3333\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1613 - accuracy: 0.9714 - val_loss: 5.7741 - val_accuracy: 0.3333\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1442 - accuracy: 0.9714 - val_loss: 5.7563 - val_accuracy: 0.4444\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1277 - accuracy: 0.9714 - val_loss: 5.7317 - val_accuracy: 0.4444\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1131 - accuracy: 0.9714 - val_loss: 5.7026 - val_accuracy: 0.4444\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0995 - accuracy: 1.0000 - val_loss: 5.6869 - val_accuracy: 0.4444\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0876 - accuracy: 1.0000 - val_loss: 5.6941 - val_accuracy: 0.4444\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0777 - accuracy: 1.0000 - val_loss: 5.7051 - val_accuracy: 0.4444\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0695 - accuracy: 1.0000 - val_loss: 5.7191 - val_accuracy: 0.4444\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0623 - accuracy: 1.0000 - val_loss: 5.7394 - val_accuracy: 0.4444\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0561 - accuracy: 1.0000 - val_loss: 5.7642 - val_accuracy: 0.4444\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0508 - accuracy: 1.0000 - val_loss: 5.7927 - val_accuracy: 0.4444\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0463 - accuracy: 1.0000 - val_loss: 5.8244 - val_accuracy: 0.4444\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0425 - accuracy: 1.0000 - val_loss: 5.8580 - val_accuracy: 0.4444\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0392 - accuracy: 1.0000 - val_loss: 5.8935 - val_accuracy: 0.4444\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0364 - accuracy: 1.0000 - val_loss: 5.9303 - val_accuracy: 0.4444\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0338 - accuracy: 1.0000 - val_loss: 5.9684 - val_accuracy: 0.4444\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 6.0091 - val_accuracy: 0.4444\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 6.0488 - val_accuracy: 0.4444\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0278 - accuracy: 1.0000 - val_loss: 6.0870 - val_accuracy: 0.4444\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0262 - accuracy: 1.0000 - val_loss: 6.1377 - val_accuracy: 0.4444\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0247 - accuracy: 1.0000 - val_loss: 6.1859 - val_accuracy: 0.4444\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0233 - accuracy: 1.0000 - val_loss: 6.2299 - val_accuracy: 0.4444\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 6.2688 - val_accuracy: 0.4444\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 6.3027 - val_accuracy: 0.4444\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 6.3321 - val_accuracy: 0.4444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2b3c2f670>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# # Define LSTM model\n",
    "# model = models.Sequential([\n",
    "#     layers.LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "#     layers.Dense(len(np.unique(y)), activation='relu')\n",
    "# ])\n",
    "\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss='sparse_categorical_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# model = models.Sequential([\n",
    "#     layers.Conv1D(filters=8, kernel_size=3, activation='relu', input_shape=input_shape),\n",
    "#     layers.MaxPooling1D(pool_size=2),\n",
    "    \n",
    "#     layers.Conv1D(filters=16, kernel_size=3, activation='relu'),\n",
    "#     layers.MaxPooling1D(pool_size=2),\n",
    "    \n",
    "#     layers.Flatten(),\n",
    "    \n",
    "#     # A small Dense layer acts as the decision layer\n",
    "#     layers.Dense(16, activation='relu'),\n",
    "    \n",
    "#     # Output layer for 12 categories. Using softmax for multi-class classification\n",
    "#     layers.Dense(num_classes, activation='softmax')\n",
    "# ])\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Flatten(input_shape=input_shape),  # Flatten the input data\n",
    "    layers.Dense(64, activation='relu'),  # First fully connected layer\n",
    "    layers.Dense(32, activation='relu'),  # Second fully connected layer\n",
    "    layers.Dense(num_classes, activation='softmax')  # Output layer for 12 categories\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Compiling the model\n",
    "# model.compile(\n",
    "#     optimizer='adam',\n",
    "#     loss='sparse_categorical_crossentropy',\n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=64, validation_split=0.2) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/gg/10wpd3jj5v7dthydfjzl0gcm0000gn/T/tmpm9b7s1p8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/gg/10wpd3jj5v7dthydfjzl0gcm0000gn/T/tmpm9b7s1p8/assets\n",
      "2023-10-17 15:50:12.344669: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2023-10-17 15:50:12.344685: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2023-10-17 15:50:12.344789: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /var/folders/gg/10wpd3jj5v7dthydfjzl0gcm0000gn/T/tmpm9b7s1p8\n",
      "2023-10-17 15:50:12.345368: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2023-10-17 15:50:12.345373: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /var/folders/gg/10wpd3jj5v7dthydfjzl0gcm0000gn/T/tmpm9b7s1p8\n",
      "2023-10-17 15:50:12.347249: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2023-10-17 15:50:12.373430: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /var/folders/gg/10wpd3jj5v7dthydfjzl0gcm0000gn/T/tmpm9b7s1p8\n",
      "2023-10-17 15:50:12.380484: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 35688 microseconds.\n"
     ]
    }
   ],
   "source": [
    "# converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# tflite_model_test = converter.convert()\n",
    "\n",
    "# with open(\"model.tflite\", \"wb\") as f:\n",
    "#     f.write(tflite_model_test)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# Allow for TensorFlow ops that aren't natively supported in TFLite\n",
    "# converter.target_spec.supported_ops = [\n",
    "#     tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "#     tf.lite.OpsSet.SELECT_TF_OPS\n",
    "# ]\n",
    "\n",
    "# # Disable the lowering of tensor list operations\n",
    "# converter._experimental_lower_tensor_list_ops = False\n",
    "\n",
    "tflite_model_test = converter.convert()\n",
    "\n",
    "with open(exported_path + \"model_dense.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdiot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
